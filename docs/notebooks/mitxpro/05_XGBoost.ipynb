{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QewGpVa0SrTQ"
   },
   "source": [
    "# Predictive Modeling with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XXV5kGO8vUB"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/noportman/noportman.github.io/blob/main/docs/notebooks/05_XGBoost.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTbSbWbmUdS5"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "An end-to-end workflow using NumPy, Pandas, Matplotlib, and XGBoost to evaluate model performance with ROC AUC, accuracy, and regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jG788--CyExN"
   },
   "source": [
    "## Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQgimFZZrHoB"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8bltmBFJYz0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FogyAYe1x87M"
   },
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECRJiTWPBAKi"
   },
   "source": [
    "Using the LendingClub loans dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n38gY_0gJivd"
   },
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/10L8BpkV4q1Zsou4daYoWul_8PFA9rsv2/export?format=csv&id=10L8BpkV4q1Zsou4daYoWul_8PFA9rsv2&gid=1710894028\"\n",
    "df = pd.read_csv(url, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlmFmwdX8Qfl",
    "outputId": "f54f532b-eae2-407f-9091-be76ae484403"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "dA0BhU6gJ5cj",
    "outputId": "afac0e43-48ca-4f4a-b7b9-dea78b5dae08"
   },
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "5KgU2bXyOFF2",
    "outputId": "31123a5b-66e1-4152-d7d1-ca43a936171b"
   },
   "outputs": [],
   "source": [
    "df.default.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrewHH7y8KDe"
   },
   "source": [
    "## Training and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8af35eyn8GB"
   },
   "source": [
    "Let's split the data 70/30 into a training set (which we will use to build models) and a test set (on which we will evaluate any model we build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyBIwHqz9twA",
    "outputId": "68727813-9391-4d3d-b760-3fe7df38726c"
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"default\"], axis=1)\n",
    "y = df[\"default\"]\n",
    "\n",
    "\n",
    "# Encode string class values as integers to avoid errors in newer versions of XGBoost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(y)\n",
    "y = label_encoder.transform(y)\n",
    "\n",
    "\n",
    "# Splitting data into training and test set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "eval_set = [(X_test, y_test)]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vljE7_ab_0Ag",
    "outputId": "a5ac551a-f75e-4eb4-8ae9-60c2de537d90"
   },
   "outputs": [],
   "source": [
    "print(\"Initializing xgboost.sklearn.XGBClassifier and starting training...\")\n",
    "\n",
    "st = datetime.now()\n",
    "\n",
    "clf = xgboost.sklearn.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    learning_rate=0.05,\n",
    "    seed=9616,\n",
    "    max_depth=20,\n",
    "    gamma=10,\n",
    "    n_estimators=500,\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=eval_set,\n",
    "    eval_metric=\"auc\",\n",
    "    early_stopping_rounds=20,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(f\"Training time: {datetime.now() - st}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(datetime.now() - st)\n",
    "\n",
    "accuracy = accuracy_score(np.array(y_test).flatten(), y_pred)\n",
    "print(\"Accuracy: %.10f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy_per_roc_auc = roc_auc_score(np.array(y_test).flatten(), y_pred)\n",
    "print(\"ROC-AUC: %.10f%%\" % (accuracy_per_roc_auc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "lLtgBOFOS2JB",
    "outputId": "f72274bb-8021-45bf-a570-2215b08600db"
   },
   "outputs": [],
   "source": [
    "# Remember: The F score is based on how often a feature is used to split the data across all trees in the model, so this gives you a relative sense of importance, not causality.\n",
    "\n",
    "xgboost.plot_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHt5pgdhDBWz"
   },
   "source": [
    "## Model Interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpMmGzCvCKl2"
   },
   "source": [
    "\n",
    "\n",
    "**1. Top Predictive Features:**\n",
    "\n",
    "`fico_score` is by far the most important feature (F score: 83), suggesting that the model heavily relies on creditworthiness when predicting the target (or likely default).\n",
    "\n",
    "`installment` (72) and `rev_balance` (58) are also strongly predictive — indicating that loan repayment terms and revolving balance significantly influence the model's decision-making.\n",
    "\n",
    "**2. Moderately Important Features:**\n",
    "\n",
    "`inquiries` (52) and `log_income` (47) contribute meaningfully, possibly capturing borrower activity and financial capability.\n",
    "\n",
    "**3. Low Importance Feature:**\n",
    "\n",
    "`records` (11) contributes very little to the model. This might mean it either has little variance or isn’t strongly correlated with default risk."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
