{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGL2uOuhNoYV"
      },
      "source": [
        "# Binary Classification on Tabular Data - Predicting Abnormal ECG Scans\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R08X1ZTM7Q7R"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/noportman/mitxpro/blob/main/binary_classification.ipynb)\n",
        "\n",
        "![Python](https://img.shields.io/badge/Python-3.10-blue)\n",
        "![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)\n",
        "![Keras](https://img.shields.io/badge/Keras-Deep%20Learning-red?logo=keras)\n",
        "![NumPy](https://img.shields.io/badge/NumPy-Numerical%20Computing-orange?logo=numpy)\n",
        "![Pandas](https://img.shields.io/badge/Pandas-Data%20Wrangling-lightgrey?logo=pandas)\n",
        "![Matplotlib](https://img.shields.io/badge/Matplotlib-Data%20Viz-blue?logo=matplotlib)\n",
        "![Scikit-Learn](https://img.shields.io/badge/scikit--learn-ML%20Toolkit-f7931e?logo=scikit-learn)\n",
        "\n",
        "![Status](https://img.shields.io/badge/Status-Completed-brightgreen)\n",
        "![License](https://img.shields.io/badge/License-MIT-yellow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m0fkGCQNlzc"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, you will train an autoencoder to detect anomalies on the ECG5000 dataset. This dataset contains 5,000 Electrocardiograms, each with 140 data points. You will use a simplified version of the dataset, where each example has been labeled either 0 (corresponding to an abnormal rhythm), or 1 (corresponding to a normal rhythm). You are interested in identifying the abnormal rhythms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8us-geJNrrP"
      },
      "source": [
        "## Technical preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-5CngkPJs8N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# initialize the seeds of different random number generators so that the\n",
        "# results will be the same every time the notebook is run\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0c6Oy0gNxD5"
      },
      "source": [
        "## Read in the data\n",
        "\n",
        "Conveniently, the dataset in CSV form has been made available online and we can load it into a Pandas dataframe with the very useful `pd.read_csv` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ngn4J7WJ9Br"
      },
      "outputs": [],
      "source": [
        "#Because each column of data represents a datapoint we will name the columns by the sequence of datapoints\n",
        "# (1,2,3...140)\n",
        "names = []\n",
        "for i in range(140):\n",
        "    names.append(i)\n",
        "# The last column will be the target or dependent variable\n",
        "names.append('Target')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbrLzn0GNu9C"
      },
      "source": [
        "#### Read in the data from http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv and set the column names from the list created in the box above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69e7I9U4J-eI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv\", header=None)\n",
        "\n",
        "df.columns = names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg0SoQQhJ_mF",
        "outputId": "51c197d3-bf86-42e3-8e6c-e999661a7005"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "g7blr1l5KCM2",
        "outputId": "628a76d5-b67c-41a7-d585-afe03e69f528"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOvYP5QEN2hJ"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "This dataset only has numeric variables. For consistency sake, we will assign the column names to variable numerics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LRCqYc3KD85"
      },
      "outputs": [],
      "source": [
        "numerics = names\n",
        "\n",
        "# Remove the dependent variable\n",
        "numerics.remove('Target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59OT36o0KF9E",
        "outputId": "4814fcaf-16d0-49c2-efbd-65d02d7b0748"
      },
      "outputs": [],
      "source": [
        "# Set the output to \"target_metrics\"\n",
        "target_metrics = df.Target.value_counts(normalize=True)\n",
        "print(target_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daMUPoXGN4mA"
      },
      "source": [
        "###### Extract the dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF_RSWlhKHWB"
      },
      "outputs": [],
      "source": [
        "#set the dependent variables to 'y'\n",
        "y = df.pop('Target')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtSM3jC9N6x-"
      },
      "source": [
        "\n",
        "Before we normalize the numerics, let's split the data into an 80% training set and 20% test set (*why should we split **before** normalization?*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ98B7TYLJXz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvnzP1g4MyaK"
      },
      "outputs": [],
      "source": [
        "#split into train and test sets with the following naming conventions:\n",
        "# X_train, X_test, y_train and y_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVzpUbd8N91U"
      },
      "source": [
        "OK, let's calculate the mean and standard deviation of every numeric variable in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVC_38G3Mzb7",
        "outputId": "e48148ad-5c20-4803-ceaa-ac64df44a7aa"
      },
      "outputs": [],
      "source": [
        "# Assign the means to \"means\" and standard deviation to \"sd\"\n",
        "means = X_train[numerics].mean()\n",
        "sd = X_train[numerics].std()\n",
        "print(means)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StF7K6INOB5N"
      },
      "source": [
        "Let's normalize the train and test dataframes with these means and standard deviations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiIH6RKKM0s5"
      },
      "outputs": [],
      "source": [
        "# Normalize X_train\n",
        "X_train[numerics]= (X_train[numerics] - means)/sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjeGnoNPM1p1"
      },
      "outputs": [],
      "source": [
        "# Normalize X_test\n",
        "X_test[numerics]= (X_test[numerics] - means)/sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "zgZrGpNHM3ld",
        "outputId": "fd621d37-84fe-466e-ebd7-af5d4463c414"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEQ1Wv_6OGA0"
      },
      "source": [
        "The easiest way to feed data to Keras/Tensorflow is as Numpy arrays so we convert our two dataframes to Numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSwABxJdM5GZ"
      },
      "outputs": [],
      "source": [
        "# Convert X_train and X_test to Numpy arrays\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztIqv5SqM7Xd",
        "outputId": "1c8236db-9ad9-4d4f-f1cb-b7de1d2e4cf3"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaUEkDihM8hw",
        "outputId": "e1222b20-e350-4570-c5d9-76028d1620d2"
      },
      "outputs": [],
      "source": [
        "X_test.shape, y_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPUha4P7NBJb"
      },
      "source": [
        "## Build a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD_B8dueNFt7"
      },
      "source": [
        "### Define model in Keras\n",
        "\n",
        "Creating an NN  is usually just a few lines of Keras code.\n",
        "\n",
        "* We will start with a single hidden layer.\n",
        "* Since this is a *binary classification problem*, we will use a sigmoid activation in the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9pzwAN6M_H1"
      },
      "outputs": [],
      "source": [
        "#get the number of columns and assign it to \"num_columns\"\n",
        "\n",
        "num_columns = X_train.shape[1]\n",
        "\n",
        "# Define the input layer. assign it to \"input\"\n",
        "input = keras.Input(shape=(num_columns,), dtype=\"float32\")\n",
        "\n",
        "# Feed the input vector to the hidden layer. Call it \"h\"\n",
        "h = keras.layers.Dense(16, activation=\"relu\", name=\"Hidden\")(input)\n",
        "\n",
        "# Feed the output of the hidden layer to the output layer. Call it \"output\"\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"Output\")(h)\n",
        "\n",
        "# tell Keras that this (input,output) pair is your model. Call it \"model\"\n",
        "model = keras.Model(input, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "3fMS6UNRNPTM",
        "outputId": "c65698fc-40a6-4883-9306-bcad210b9f98"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "Yc8O98MMNQpc",
        "outputId": "9d6bf164-1f54-4beb-cc6d-2438eec2a54f"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMgPc5JHNS10"
      },
      "source": [
        "### Set optimization parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp-OjU_NNUfp"
      },
      "source": [
        "Now that the model is defined, we need to tell Keras three things:\n",
        "\n",
        "*   What **loss function** to use - Since our output variable is binary, we will select the `binary_crossentropy` loss function.\n",
        "*   Which **optimizer** to use - we will use a 'flavor' of SGD called `adam` which is an excellent default choice\n",
        "*   What **metrics** you want Keras to report out - in classification problems like this one, `accuracy` is commonly used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EF-hI65NUO4"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxn98eWdNXD8"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "To kickoff training, we have to decide on three things:\n",
        "* The *batch size* - 32 is a good default\n",
        "* The number of *epochs* (i.e., how many passes through the training data). Start by setting this to 100, but you can experiment with different values.\n",
        "* Whether we want to use a validation set. This will be useful for overfitting detection and regularization via early stopping so we will ask Keras to automatically use 20% of the data points as a validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7eVZfydNZJT",
        "outputId": "f006cb51-a2cd-4a7a-ca23-499260a48282"
      },
      "outputs": [],
      "source": [
        "# Fit your model and assign the output to \"history\"\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdCSQmVINbhS",
        "outputId": "01dc7a66-b0c1-42da-d414-22ff22c1475c"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WD0auO73NcY1",
        "outputId": "3f1990d9-417b-4ef9-deae-b04f9e5bd4c4"
      },
      "outputs": [],
      "source": [
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tcOkjBScNdyf",
        "outputId": "5194f6ba-a891-4368-af2c-618539068b52"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS8iR5tTNfpT"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "Let's see **how well the model does on the test set**.\n",
        "\n",
        "`model.evaluate` is a very handy function to calculate the performance of your model on any dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHaJ8-XmNgKX",
        "outputId": "cea5ecd8-cb74-4dcd-8665-268ea4cf979a"
      },
      "outputs": [],
      "source": [
        "# Getting the results of your model for grading\n",
        "score, acc = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "vk0Wto1jNiP9",
        "outputId": "5f2468c6-0486-4473-c509-197e6fc8775e"
      },
      "outputs": [],
      "source": [
        "y.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "5JvDAkbKMC2_",
        "outputId": "3c4466bc-d92c-43f3-c574-ad8cccf09755"
      },
      "outputs": [],
      "source": [
        "# Selecting a specific row (e.g., row index 300)\n",
        "row_index = 300\n",
        "y_values = X_train[row_index, :]\n",
        "x_values = range(X_train.shape[1])  # X-axis: 0 to 139\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x_values, y_values, marker='o', linestyle='-')\n",
        "plt.xlabel(\"X-Axis (Index)\")\n",
        "plt.ylabel(\"Y-Axis (Values)\")\n",
        "plt.title(f\"Plot of Row {row_index}\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faYbTVGMNH2H",
        "outputId": "288ba13c-5d68-4e5d-925d-c37d86e055eb"
      },
      "outputs": [],
      "source": [
        "print(y_train[row_index])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mkdocs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
